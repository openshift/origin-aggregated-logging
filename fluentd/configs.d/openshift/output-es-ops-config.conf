    <store>
      @type elasticsearch_dynamic
      host "#{ENV['OPS_HOST']}"
      port "#{ENV['OPS_PORT']}"
      scheme https
      index_name .operations.${begin record['@timestamp'].nil? ? Time.at(time).getutc.strftime(@logstash_dateformat) : Time.parse(record['@timestamp']).getutc.strftime(@logstash_dateformat) rescue $log.error("record is missing time and @timestamp - record " + record.to_s) end}
      user fluentd
      password changeme

      client_key "#{ENV['OPS_CLIENT_KEY']}"
      client_cert "#{ENV['OPS_CLIENT_CERT']}"
      ca_file "#{ENV['OPS_CA']}"

      type_name com.redhat.viaq.common

      # there is currently a bug in the es plugin + excon - cannot
      # recreate/reload connections
      reload_connections false
      reload_on_failure false
      flush_interval "#{ENV['OPS_FLUSH_INTERVAL'] || ENV['ES_FLUSH_INTERVAL'] || '5s'}"
      max_retry_wait "#{ENV['OPS_RETRY_WAIT'] || ENV['ES_RETRY_WAIT'] || '300'}"
      disable_retry_limit true
      buffer_queue_limit "#{ENV['BUFFER_QUEUE_LIMIT'] || '1024' }"
      buffer_chunk_limit "#{ENV['BUFFER_SIZE_LIMIT'] || '1m' }"
      # the systemd journald 0.0.8 input plugin will just throw away records if the buffer
      # queue limit is hit - 'block' will halt further reads and keep retrying to flush the
      # buffer to the remote - default is 'exception' because in_tail handles that case
      buffer_queue_full_action "#{ENV['BUFFER_QUEUE_FULL_ACTION'] || 'exception'}"
    </store>
