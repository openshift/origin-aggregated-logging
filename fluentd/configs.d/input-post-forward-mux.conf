<source>
  @type secure_forward
  @label @MUX
  port "#{ENV['FORWARD_LISTEN_PORT'] || '24284'}"
  # bind 0.0.0.0 # default
  log_level "#{ENV['FORWARD_INPUT_LOG_LEVEL'] || ENV['LOG_LEVEL'] || 'warn'}"
  self_hostname "#{ENV['FORWARD_LISTEN_HOST'] || 'mux.example.com'}"
  shared_key    "#{File.open('/etc/fluent/muxkeys/shared_key') do |f| f.readline end.rstrip}"

  secure yes

  cert_path        /etc/fluent/muxkeys/cert
  private_key_path /etc/fluent/muxkeys/key
  private_key_passphrase not_used_key_is_unencrypted
</source>

<label @MUX>
  # these are usually coming as raw logs from an openshift fluentd acting
  # as a collector only
  # specifically - an openshift fluentd collector configured to use secure_forward as
  # described in https://github.com/openshift/origin-aggregated-logging/pull/264/files

  # mux hardcodes USE_JOURNAL=true to force the k8s-meta plugin to look for
  # CONTAINER_NAME instead of the tag to extract the k8s metadata - logs coming
  # from a fluentd using json-file will usually not have these fields, so add them
  <filter kubernetes.var.log.containers.**>
    @type record_transformer
    enable_ruby
    <record>
      CONTAINER_NAME ${record['CONTAINER_NAME'] || (md = /var\.log\.containers\.(?<pod_name>[a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*)_(?<namespace>[^_]+)_(?<container_name>.+)-(?<docker_id>[a-z0-9]{64})\.log$/.match(tag); "k8s_" + md["container_name"] + ".0_" + md["pod_name"] + "_" + md["namespace"] + "_0_01234567")}
      CONTAINER_ID_FULL ${record['CONTAINER_ID_FULL'] || (md = /var\.log\.containers\.(?<pod_name>[a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*)_(?<namespace>[^_]+)_(?<container_name>.+)-(?<docker_id>[a-z0-9]{64})\.log$/.match(tag); md["docker_id"])
    </record>
  </filter>

  # just redirect these to their standard processing/filtering
  <match journal system.var.log.messages system.var.log.messages.** kubernetes.var.log.containers.**>
    @type relabel
    @label @INGRESS
  </match>

  # Records with these tags are operations logs and have already been processed
  # and formatted by an openshift fluentd, so we can skip any additional
  # processing
  <match journal.container** journal.system>
    @type rewrite_tag_filter
    @label @INGRESS
    rewriterule1 message .+ mux.ops
  </match>

  # if mux is operating as an external facing service, there is more
  # processing required
  @include mux-post-input-*.conf
</label>
